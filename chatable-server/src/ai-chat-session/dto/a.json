{
  "object": "list",
  "data": [
    {
      "id": "theb-ai",
      "name": "TheB.AI",
      "family": "chat",
      "desc": "Optimized conversation model, faster response, more natural and vivid language. Powered by gpt-4o-mini.",
      "params": [
        { "name": "temperature", "label": "Temperature", "type": "number", "max": "2", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "top_p", "label": "Top P", "type": "number", "max": "1", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "frequency_penalty", "label": "Frequency Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" },
        { "name": "presence_penalty", "label": "Presence Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" }
      ],
      "pricing": { "type": "per_token", "input": "0.0000005", "output": "0.0000005" }
    },
    {
      "id": "theb-ai-4",
      "name": "TheB.AI 4.0",
      "family": "chat",
      "desc": "Upgraded version of TheB.AI model, optimized for conversations, with faster response, more natural and vivid language. Powered by Mixed Model Routing (GPT-4o, Claude 3.5 Sonnet, Llama 3.1 405B).",
      "params": [
        { "name": "temperature", "label": "Temperature", "type": "number", "max": "2", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "top_p", "label": "Top P", "type": "number", "max": "1", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "frequency_penalty", "label": "Frequency Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" },
        { "name": "presence_penalty", "label": "Presence Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" }
      ],
      "pricing": { "type": "per_token", "input": "0.0000025", "output": "0.00001" }
    },
    {
      "id": "gpt-3.5-turbo",
      "name": "GPT-3.5 Turbo",
      "family": "chat",
      "desc": "Capable of solving most everyday problems or providing entertainment, with 16k context.",
      "params": [
        { "name": "temperature", "label": "Temperature", "type": "number", "max": "2", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "top_p", "label": "Top P", "type": "number", "max": "1", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "frequency_penalty", "label": "Frequency Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" },
        { "name": "presence_penalty", "label": "Presence Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" }
      ],
      "pricing": { "type": "per_token", "input": "0.0000005", "output": "0.0000015" }
    },
    {
      "id": "gpt-4o",
      "name": "GPT-4 Omni",
      "family": "chat",
      "desc": "GPT-4 Omni matches GPT-4 Turbo performance on text in English and code, with significant improvement on text in non-English languages, while also being much faster and 50% cheaper.",
      "params": [
        { "name": "temperature", "label": "Temperature", "type": "number", "max": "2", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "top_p", "label": "Top P", "type": "number", "max": "1", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "frequency_penalty", "label": "Frequency Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" },
        { "name": "presence_penalty", "label": "Presence Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" }
      ],
      "pricing": { "type": "per_token", "input": "0.000005", "output": "0.000015" }
    },
    {
      "id": "gpt-4o-mini",
      "name": "GPT-4 Omni Mini",
      "family": "chat",
      "desc": "Longer context length and output length lead to higher performance than GPT-3.5-Turbo.",
      "params": [
        { "name": "temperature", "label": "Temperature", "type": "number", "max": "2", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "top_p", "label": "Top P", "type": "number", "max": "1", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "frequency_penalty", "label": "Frequency Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" },
        { "name": "presence_penalty", "label": "Presence Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" }
      ],
      "pricing": { "type": "per_token", "input": "0.00000015", "output": "0.0000006" }
    },
    {
      "id": "gpt-4-turbo",
      "name": "GPT-4 Turbo",
      "family": "chat",
      "desc": "OpenAI's most advanced system demonstrates excellent performance on most questions and operates swiftly, boasting a context capacity of 128k.",
      "params": [
        { "name": "temperature", "label": "Temperature", "type": "number", "max": "2", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "top_p", "label": "Top P", "type": "number", "max": "1", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "frequency_penalty", "label": "Frequency Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" },
        { "name": "presence_penalty", "label": "Presence Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" }
      ],
      "pricing": { "type": "per_token", "input": "0.00001", "output": "0.00003" }
    },
    {
      "id": "gpt-4",
      "name": "GPT-4 Classic",
      "family": "chat",
      "desc": "Classic version of GPT-4 - Excellent performance on most questions. Note that this model is more expensive than GPT-4 Turbo.",
      "params": [
        { "name": "temperature", "label": "Temperature", "type": "number", "max": "2", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "top_p", "label": "Top P", "type": "number", "max": "1", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "frequency_penalty", "label": "Frequency Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" },
        { "name": "presence_penalty", "label": "Presence Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" }
      ],
      "pricing": { "type": "per_token", "input": "0.00003", "output": "0.00006" }
    },
    {
      "id": "claude-3-haiku",
      "name": "Claude 3 Haiku",
      "family": "chat",
      "desc": "Claude 3 Haiku Anthropic's our fastest, most compact model for near-instant responsiveness. It answers simple queries and requests with unmatched speed.",
      "params": [
        { "name": "temperature", "label": "Temperature", "type": "number", "max": "2", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "top_p", "label": "Top P", "type": "number", "max": "1", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "frequency_penalty", "label": "Frequency Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" },
        { "name": "presence_penalty", "label": "Presence Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" }
      ],
      "pricing": { "type": "per_token", "input": "0.00000025", "output": "0.00000125" }
    },
    {
      "id": "claude-3-sonnet",
      "name": "Claude 3 Sonnet",
      "family": "chat",
      "desc": "Claude 3 Sonnet strikes the ideal balance between intelligence and speed, it delivers strong performance at a lower cost compared to its peers, and is engineered for high endurance in large-scale AI deployments.",
      "params": [
        { "name": "temperature", "label": "Temperature", "type": "number", "max": "2", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "top_p", "label": "Top P", "type": "number", "max": "1", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "frequency_penalty", "label": "Frequency Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" },
        { "name": "presence_penalty", "label": "Presence Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" }
      ],
      "pricing": { "type": "per_token", "input": "0.000003", "output": "0.000015" }
    },
    {
      "id": "claude-3.5-sonnet",
      "name": "Claude 3.5 Sonnet",
      "family": "chat",
      "desc": "Claude 3.5 Sonnet operates at twice the speed of Claude 3 Opus. And even smarter than Claude 3 Opus at a cost-effective pricing.",
      "params": [
        { "name": "temperature", "label": "Temperature", "type": "number", "max": "2", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "top_p", "label": "Top P", "type": "number", "max": "1", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "frequency_penalty", "label": "Frequency Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" },
        { "name": "presence_penalty", "label": "Presence Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" }
      ],
      "pricing": { "type": "per_token", "input": "0.000003", "output": "0.000015" }
    },
    {
      "id": "claude-3-opus",
      "name": "Claude 3 Opus",
      "family": "chat",
      "desc": "Claude 3 Opus is Anthropic's most intelligent model, with best-in-market performance on highly complex tasks. Opus shows us the outer limits of whatâ€™s possible with generative AI.",
      "params": [
        { "name": "temperature", "label": "Temperature", "type": "number", "max": "2", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "top_p", "label": "Top P", "type": "number", "max": "1", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "frequency_penalty", "label": "Frequency Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" },
        { "name": "presence_penalty", "label": "Presence Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" }
      ],
      "pricing": { "type": "per_token", "input": "0.000015", "output": "0.000075" }
    },
    {
      "id": "gemini-1.5-flash",
      "name": "Gemini 1.5 Pro",
      "family": "chat",
      "desc": "Google's fastest model boasts excellent performance in translation, text analysis, and other tasks.",
      "params": [
        { "name": "temperature", "label": "Temperature", "type": "number", "max": "2", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "top_p", "label": "Top P", "type": "number", "max": "1", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "frequency_penalty", "label": "Frequency Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" },
        { "name": "presence_penalty", "label": "Presence Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" }
      ],
      "pricing": { "type": "per_token", "input": "0.0000007", "output": "0.0000021" }
    },
    {
      "id": "gemini-1.5-pro",
      "name": "Gemini 1.5 Pro",
      "family": "chat",
      "desc": "Google's most advanced model boasts excellent performance in translation, text analysis, and other tasks.",
      "params": [
        { "name": "temperature", "label": "Temperature", "type": "number", "max": "2", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "top_p", "label": "Top P", "type": "number", "max": "1", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "frequency_penalty", "label": "Frequency Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" },
        { "name": "presence_penalty", "label": "Presence Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" }
      ],
      "pricing": { "type": "per_token", "input": "0.000007", "output": "0.000021" }
    },
    {
      "id": "gemma-2-9b",
      "name": "Gemma 2 9B",
      "family": "chat",
      "desc": "Gemma 2 9B Gemma is a family of lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models.",
      "params": [
        { "name": "temperature", "label": "Temperature", "type": "number", "max": "2", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "top_p", "label": "TopP", "type": "number", "max": "1", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "frequency_penalty", "label": "Frequency Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" },
        { "name": "presence_penalty", "label": "Presence Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" },
        {
          "name": "long_term_memory",
          "label": "Context",
          "type": "select",
          "options": [
            ["Off", "off"],
            ["Auto", "auto"],
            ["Long-term Memory", "ltm"]
          ],
          "default": "ltm"
        }
      ],
      "pricing": { "type": "per_token", "input": "0.00000015", "output": "0.0000003" }
    },
    {
      "id": "gemma-2-27b",
      "name": "Gemma 2 27B",
      "family": "chat",
      "desc": "Gemma 2 27B Gemma is a family of lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models.",
      "params": [
        { "name": "temperature", "label": "Temperature", "type": "number", "max": "2", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "top_p", "label": "TopP", "type": "number", "max": "1", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "frequency_penalty", "label": "Frequency Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" },
        { "name": "presence_penalty", "label": "Presence Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" },
        {
          "name": "long_term_memory",
          "label": "Context",
          "type": "select",
          "options": [
            ["Off", "off"],
            ["Auto", "auto"],
            ["Long-term Memory", "ltm"]
          ],
          "default": "ltm"
        }
      ],
      "pricing": { "type": "per_token", "input": "0.0000008", "output": "0.0000012" }
    },
    {
      "id": "llama-3-8b-chat",
      "name": "Llama3 8B",
      "family": "chat",
      "desc": "A large language model has been open-sourced by Meta AI, boasting an impressive 8 billion parameters.",
      "params": [
        { "name": "temperature", "label": "Temperature", "type": "number", "max": "2", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "top_p", "label": "Top P", "type": "number", "max": "1", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "frequency_penalty", "label": "Frequency Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" },
        { "name": "presence_penalty", "label": "Presence Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" }
      ],
      "pricing": { "type": "per_token", "input": "0.00000015", "output": "0.0000003" }
    },
    {
      "id": "llama-3-70b-chat",
      "name": "Llama3 8B",
      "family": "chat",
      "desc": "A large language model has been open-sourced by Meta AI, boasting an impressive 70 billion parameters.",
      "params": [
        { "name": "temperature", "label": "Temperature", "type": "number", "max": "2", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "top_p", "label": "Top P", "type": "number", "max": "1", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "frequency_penalty", "label": "Frequency Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" },
        { "name": "presence_penalty", "label": "Presence Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" }
      ],
      "pricing": { "type": "per_token", "input": "0.000001", "output": "0.0000015" }
    },
    {
      "id": "llama-3.1-8b-chat",
      "name": "Llama 3.1 8B",
      "family": "chat",
      "desc": "A large language model has been open-sourced by Meta AI, boasting an impressive 8 billion parameters.",
      "params": [
        { "name": "temperature", "label": "Temperature", "type": "number", "max": "2", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "top_p", "label": "Top P", "type": "number", "max": "1", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "frequency_penalty", "label": "Frequency Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" },
        { "name": "presence_penalty", "label": "Presence Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" }
      ],
      "pricing": { "type": "per_token", "input": "0.00000015", "output": "0.0000003" }
    },
    {
      "id": "llama-3.1-70b-chat",
      "name": "Llama 3.1 8B",
      "family": "chat",
      "desc": "A large language model has been open-sourced by Meta AI, boasting an impressive 70 billion parameters.",
      "params": [
        { "name": "temperature", "label": "Temperature", "type": "number", "max": "2", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "top_p", "label": "Top P", "type": "number", "max": "1", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "frequency_penalty", "label": "Frequency Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" },
        { "name": "presence_penalty", "label": "Presence Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" }
      ],
      "pricing": { "type": "per_token", "input": "0.000001", "output": "0.0000015" }
    },
    {
      "id": "llama-3.1-405b-chat",
      "name": "Llama 3.1 405B",
      "family": "chat",
      "desc": "A large language model has been open-sourced by Meta AI, boasting an impressive 405 billion parameters.",
      "params": [
        { "name": "temperature", "label": "Temperature", "type": "number", "max": "2", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "top_p", "label": "Top P", "type": "number", "max": "1", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "frequency_penalty", "label": "Frequency Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" },
        { "name": "presence_penalty", "label": "Presence Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" }
      ],
      "pricing": { "type": "per_token", "input": "0.000005", "output": "0.000008" }
    },
    {
      "id": "mistral-7b",
      "name": "Mistral 7B",
      "family": "chat",
      "desc": "A 7.3B parameter model that outperforms Llama 2 13B on all benchmarks, with optimizations for speed and context length.",
      "params": [
        { "name": "temperature", "label": "Temperature", "type": "number", "max": "2", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "top_p", "label": "Top P", "type": "number", "max": "1", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "frequency_penalty", "label": "Frequency Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" },
        { "name": "presence_penalty", "label": "Presence Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" }
      ],
      "pricing": { "type": "per_token", "input": "0.00000015", "output": "0.0000003" }
    },
    {
      "id": "mixtral-8x7b",
      "name": "Mixtral 8x7B",
      "family": "chat",
      "desc": "A pretrained generative Sparse Mixture of Experts, by Mistral AI. Incorporates 8 experts (feed-forward networks) for a total of 47B parameters.",
      "params": [
        { "name": "temperature", "label": "Temperature", "type": "number", "max": "2", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "top_p", "label": "Top P", "type": "number", "max": "1", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "frequency_penalty", "label": "Frequency Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" },
        { "name": "presence_penalty", "label": "Presence Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" }
      ],
      "pricing": { "type": "per_token", "input": "0.0000003", "output": "0.00000045" }
    },
    {
      "id": "mixtral-8x22b",
      "name": "Mixtral 8x22B",
      "family": "chat",
      "desc": "Mixtral 8x22B is a large-scale language model from Mistral AI. It consists of 8 experts, each 22 billion parameters, with each token using 2 experts at a time.",
      "params": [
        { "name": "temperature", "label": "Temperature", "type": "number", "max": "2", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "top_p", "label": "Top P", "type": "number", "max": "1", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "frequency_penalty", "label": "Frequency Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" },
        { "name": "presence_penalty", "label": "Presence Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" }
      ],
      "pricing": { "type": "per_token", "input": "0.000001", "output": "0.0000015" }
    },
    {
      "id": "wizardlm-2-8x22b",
      "name": "WizardLM 2 8x22B",
      "family": "chat",
      "desc": "WizardLM-2 8x22B is Microsoft AI's most advanced Wizard model based on Mixtral 8x22B. It demonstrates highly competitive performance compared to leading proprietary models.",
      "params": [
        { "name": "temperature", "label": "Temperature", "type": "number", "max": "2", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "top_p", "label": "Top P", "type": "number", "max": "1", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "frequency_penalty", "label": "Frequency Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" },
        { "name": "presence_penalty", "label": "Presence Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" }
      ],
      "pricing": { "type": "per_token", "input": "0.000001", "output": "0.0000015" }
    },
    {
      "id": "dbrx-instruct",
      "name": "DBRX Instruct",
      "family": "chat",
      "desc": "DBRX is a open source MOE large language model developed by Databricks. At 132B, it outperforms existing open source LLMs like Llama 2 70B and Mixtral-8x7B on standard industry benchmarks for language understanding, programming, math, and logic.",
      "params": [
        { "name": "temperature", "label": "Temperature", "type": "number", "max": "2", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "top_p", "label": "Top P", "type": "number", "max": "1", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "frequency_penalty", "label": "Frequency Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" },
        { "name": "presence_penalty", "label": "Presence Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" }
      ],
      "pricing": { "type": "per_token", "input": "0.000001", "output": "0.0000015" }
    },
    {
      "id": "deepseek-llm-67b",
      "name": "Deepseek LLM 67B",
      "family": "chat",
      "desc": "DeepSeek LLM is an advanced language model comprising 67 billion parameters. It has been trained from scratch on a vast dataset of 2 trillion tokens in both English and Chinese.",
      "params": [
        { "name": "temperature", "label": "Temperature", "type": "number", "max": "2", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "top_p", "label": "TopP", "type": "number", "max": "1", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "frequency_penalty", "label": "Frequency Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" },
        { "name": "presence_penalty", "label": "Presence Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" },
        {
          "name": "long_term_memory",
          "label": "Context",
          "type": "select",
          "options": [
            ["Off", "off"],
            ["Auto", "auto"],
            ["Long-term Memory", "ltm"]
          ],
          "default": "ltm"
        }
      ],
      "pricing": { "type": "per_token", "input": "0.000001", "output": "0.0000015" }
    },
    {
      "id": "yi-34b",
      "name": "Yi 34B",
      "family": "chat",
      "desc": "The Yi series models are large language models trained from scratch by developers at 01.AI.",
      "params": [
        { "name": "temperature", "label": "Temperature", "type": "number", "max": "2", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "top_p", "label": "Top P", "type": "number", "max": "1", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "frequency_penalty", "label": "Frequency Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" },
        { "name": "presence_penalty", "label": "Presence Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" }
      ],
      "pricing": { "type": "per_token", "input": "0.0000008", "output": "0.0000012" }
    },
    {
      "id": "qwen-2-72b",
      "name": "Qwen2 72B",
      "family": "chat",
      "desc": "Qwen2 is the large language model series developed by Qwen team, Alibaba Cloud. With higher performance than Qwen1.5.",
      "params": [
        { "name": "temperature", "label": "Temperature", "type": "number", "max": "2", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "top_p", "label": "Top P", "type": "number", "max": "1", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "frequency_penalty", "label": "Frequency Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" },
        { "name": "presence_penalty", "label": "Presence Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" }
      ],
      "pricing": { "type": "per_token", "input": "0.000001", "output": "0.0000015" }
    },
    {
      "id": "qwen-1.5-7b",
      "name": "Qwen1.5 7B",
      "family": "chat",
      "desc": "Qwen1.5 is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data. Qwen1.5 7B is a 7B model from Qwen1.5 family.",
      "params": [
        { "name": "temperature", "label": "Temperature", "type": "number", "max": "2", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "top_p", "label": "Top P", "type": "number", "max": "1", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "frequency_penalty", "label": "Frequency Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" },
        { "name": "presence_penalty", "label": "Presence Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" }
      ],
      "pricing": { "type": "per_token", "input": "0.00000015", "output": "0.0000003" }
    },
    {
      "id": "qwen-1.5-14b",
      "name": "Qwen1.5 14B",
      "family": "chat",
      "desc": "Qwen1.5 is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data. Qwen1.5 14B is a 14B model from Qwen1.5 family.",
      "params": [
        { "name": "temperature", "label": "Temperature", "type": "number", "max": "2", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "top_p", "label": "Top P", "type": "number", "max": "1", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "frequency_penalty", "label": "Frequency Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" },
        { "name": "presence_penalty", "label": "Presence Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" }
      ],
      "pricing": { "type": "per_token", "input": "0.0000003", "output": "0.00000045" }
    },
    {
      "id": "qwen-1.5-32b",
      "name": "Qwen1.5 32B",
      "family": "chat",
      "desc": "Qwen1.5 is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data. Qwen1.5 32B is a 32B model from Qwen1.5 family.",
      "params": [
        { "name": "temperature", "label": "Temperature", "type": "number", "max": "2", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "top_p", "label": "Top P", "type": "number", "max": "1", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "frequency_penalty", "label": "Frequency Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" },
        { "name": "presence_penalty", "label": "Presence Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" }
      ],
      "pricing": { "type": "per_token", "input": "0.0000008", "output": "0.0000012" }
    },
    {
      "id": "qwen-1.5-72b",
      "name": "Qwen1.5 72B",
      "family": "chat",
      "desc": "Qwen1.5 is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data. Qwen1.5 72B is a 72B model from Qwen1.5 family.",
      "params": [
        { "name": "temperature", "label": "Temperature", "type": "number", "max": "2", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "top_p", "label": "Top P", "type": "number", "max": "1", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "frequency_penalty", "label": "Frequency Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" },
        { "name": "presence_penalty", "label": "Presence Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" }
      ],
      "pricing": { "type": "per_token", "input": "0.000001", "output": "0.0000015" }
    },
    {
      "id": "qwen-1.5-110b",
      "name": "Qwen1.5 110B",
      "family": "chat",
      "desc": "Qwen1.5 is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data. Qwen1.5 110B is a 110B model from Qwen1.5 family.",
      "params": [
        { "name": "temperature", "label": "Temperature", "type": "number", "max": "2", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "top_p", "label": "Top P", "type": "number", "max": "1", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "frequency_penalty", "label": "Frequency Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" },
        { "name": "presence_penalty", "label": "Presence Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" }
      ],
      "pricing": { "type": "per_token", "input": "0.0000015", "output": "0.0000025" }
    },
    {
      "id": "llama-2-7b-chat",
      "name": "Llama2 7B",
      "family": "chat",
      "desc": "A large language model has been open-sourced by Meta AI, boasting an impressive 7 billion parameters.",
      "params": [
        { "name": "temperature", "label": "Temperature", "type": "number", "max": "2", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "top_p", "label": "Top P", "type": "number", "max": "1", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "frequency_penalty", "label": "Frequency Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" },
        { "name": "presence_penalty", "label": "Presence Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" }
      ],
      "pricing": { "type": "per_token", "input": "0.00000015", "output": "0.0000003" }
    },
    {
      "id": "llama-2-13b-chat",
      "name": "Llama2 13B",
      "family": "chat",
      "desc": "A large language model has been open-sourced by Meta AI, boasting an impressive 13 billion parameters.",
      "params": [
        { "name": "temperature", "label": "Temperature", "type": "number", "max": "2", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "top_p", "label": "Top P", "type": "number", "max": "1", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "frequency_penalty", "label": "Frequency Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" },
        { "name": "presence_penalty", "label": "Presence Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" }
      ],
      "pricing": { "type": "per_token", "input": "0.0000003", "output": "0.00000045" }
    },
    {
      "id": "llama-2-70b-chat",
      "name": "Llama2 70B",
      "family": "chat",
      "desc": "A large language model has been open-sourced by Meta AI, boasting an impressive 70 billion parameters.",
      "params": [
        { "name": "temperature", "label": "Temperature", "type": "number", "max": "2", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "top_p", "label": "Top P", "type": "number", "max": "1", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "frequency_penalty", "label": "Frequency Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" },
        { "name": "presence_penalty", "label": "Presence Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" }
      ],
      "pricing": { "type": "per_token", "input": "0.000001", "output": "0.0000015" }
    },
    {
      "id": "code-llama-7b",
      "name": "CodeLlama 7B",
      "family": "chat",
      "desc": "CodeLlama 7B is a family of large language models designed specifically for code-related tasks, based on the foundational model Llama2.",
      "params": [
        { "name": "temperature", "label": "Temperature", "type": "number", "max": "2", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "top_p", "label": "Top P", "type": "number", "max": "1", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "frequency_penalty", "label": "Frequency Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" },
        { "name": "presence_penalty", "label": "Presence Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" }
      ],
      "pricing": { "type": "per_token", "input": "0.00000015", "output": "0.0000003" }
    },
    {
      "id": "code-llama-13b",
      "name": "CodeLlama 13B",
      "family": "chat",
      "desc": "CodeLlama 13B is a family of large language models designed specifically for code-related tasks, based on the foundational model Llama2.",
      "params": [
        { "name": "temperature", "label": "Temperature", "type": "number", "max": "2", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "top_p", "label": "Top P", "type": "number", "max": "1", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "frequency_penalty", "label": "Frequency Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" },
        { "name": "presence_penalty", "label": "Presence Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" }
      ],
      "pricing": { "type": "per_token", "input": "0.0000003", "output": "0.00000045" }
    },
    {
      "id": "code-llama-34b",
      "name": "CodeLlama 34B",
      "family": "chat",
      "desc": "CodeLlama 34B is a family of large language models designed specifically for code-related tasks, based on the foundational model Llama2.",
      "params": [
        { "name": "temperature", "label": "Temperature", "type": "number", "max": "2", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "top_p", "label": "Top P", "type": "number", "max": "1", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "frequency_penalty", "label": "Frequency Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" },
        { "name": "presence_penalty", "label": "Presence Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" }
      ],
      "pricing": { "type": "per_token", "input": "0.0000008", "output": "0.0000012" }
    },
    {
      "id": "code-llama-70b",
      "name": "CodeLlama34B",
      "family": "chat",
      "desc": "CodeLlama 70B is a family of large language models designed specifically for code-related tasks, based on the foundational model Llama2.",
      "params": [
        { "name": "temperature", "label": "Temperature", "type": "number", "max": "2", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "top_p", "label": "Top P", "type": "number", "max": "1", "min": "0", "default": "1", "precision": "0.01" },
        { "name": "frequency_penalty", "label": "Frequency Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" },
        { "name": "presence_penalty", "label": "Presence Penalty", "type": "number", "min": "-2", "max": "2", "default": "0", "precision": "0.01" }
      ],
      "pricing": { "type": "per_token", "input": "0.000001", "output": "0.0000015" }
    }
  ]
}
